{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 7: TEORIA - Vectorización Completa de Monte Carlo\n",
        "\n",
        "## Objetivo\n",
        "Este notebook implementa los conceptos teóricos de vectorización completa del notebook de ejemplo (`MonteCarlo_Monos_enunciado.ipynb`), aplicándolos al contexto del Notebook 6 para maximizar la velocidad de la simulación de Monte Carlo.\n",
        "\n",
        "## Conceptos Teóricos Implementados\n",
        "1. **Multiplicación de matrices para cálculo de retornos**: Usar `(días × activos) @ (activos × monos) = (días × monos)` para calcular TODOS los retornos de TODOS los monos en una sola operación\n",
        "2. **Selección aleatoria vectorizada con argsort**: Generar matriz aleatoria `(n_monos × n_elegibles)` y usar `np.argsort` para obtener top N índices por fila\n",
        "3. **Construcción de matriz de pesos vectorizada**: Matriz de pesos `(n_monos × n_assets)` asignada usando advanced indexing vectorizado\n",
        "4. **Cálculo acumulado vectorizado**: Usar `np.sum` sobre todos los monos simultáneamente\n",
        "\n",
        "## Estrategia Híbrida\n",
        "- Pre-calcular TODAS las selecciones aleatorias para TODOS los meses de una vez (vectorizado)\n",
        "- Construir matriz de pesos y usar multiplicación de matrices para calcular retornos\n",
        "- Procesar mes a mes pero vectorizando completamente cada mes\n",
        "- Sin loops sobre monos, solo sobre meses si es necesario\n",
        "\n",
        "## Contenido\n",
        "1. Configuración y carga de datos\n",
        "2. Pre-cálculo de índices elegibles\n",
        "3. Monte Carlo con vectorización completa (multiplicación de matrices)\n",
        "4. Análisis de resultados\n",
        "5. Comparación de velocidad con Notebook 6\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuración y Carga de Datos {#configuracion}\n",
        "\n",
        "Esta sección configura el entorno y carga los datos necesarios para la simulación de Monte Carlo con vectorización completa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "NOTEBOOK 7: TEORIA - VECTORIZACIÓN COMPLETA\n",
            "======================================================================\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../datos/backtest/equity_curve.parquet'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Cargar resultados del backtesting (para comparación)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m df_equity = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATA_BACKTEST_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/equity_curve.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m df_trades = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_BACKTEST_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/trades.csv\u001b[39m\u001b[33m'\u001b[39m, parse_dates=[\u001b[33m'\u001b[39m\u001b[33mfecha\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Convertir fecha a índice para análisis temporal\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../datos/backtest/equity_curve.parquet'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from scipy import stats\n",
        "\n",
        "# Configuración\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "# Parámetros\n",
        "CAPITAL_INICIAL = 250_000\n",
        "DATA_BACKTEST_DIR = '../datos/backtest'\n",
        "DATA_PROCESSED_DIR = '../datos/processed'\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"NOTEBOOK 7: TEORIA - VECTORIZACIÓN COMPLETA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Cargar resultados del backtesting (para comparación)\n",
        "df_equity = pd.read_parquet(f'{DATA_BACKTEST_DIR}/equity_curve.parquet')\n",
        "df_trades = pd.read_csv(f'{DATA_BACKTEST_DIR}/trades.csv', parse_dates=['fecha'])\n",
        "\n",
        "# Convertir fecha a índice para análisis temporal\n",
        "df_equity['fecha'] = pd.to_datetime(df_equity['fecha'])\n",
        "df_equity = df_equity.set_index('fecha').sort_index()\n",
        "\n",
        "# Calcular retornos mensuales\n",
        "df_equity['retorno_mensual'] = df_equity['equity'].pct_change()\n",
        "\n",
        "print(f\"\\nEquity curve: {df_equity.shape}\")\n",
        "print(f\"Trades: {df_trades.shape}\")\n",
        "print(f\"Período: {df_equity.index[0].date()} a {df_equity.index[-1].date()}\")\n",
        "print(f\"Capital inicial: ${CAPITAL_INICIAL:,.0f}\")\n",
        "print(f\"Capital final: ${df_equity['equity'].iloc[-1]:,.0f}\")\n",
        "print(f\"Retorno total: {(df_equity['equity'].iloc[-1] / CAPITAL_INICIAL - 1) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carga de Datos para Monte Carlo {#carga-datos}\n",
        "\n",
        "Carga de datos necesarios para la simulación de Monte Carlo con eligibility mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CARGANDO DATOS PARA MONTE CARLO\n",
            "======================================================================\n",
            "Retornos para MC: (133, 845)\n",
            "Eligibility mask: (133, 845)\n",
            "Fechas rebalanceo: 133\n",
            "\n",
            "✓ Datos cargados correctamente\n"
          ]
        }
      ],
      "source": [
        "# Cargar datos para MC\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CARGANDO DATOS PARA MONTE CARLO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Cargar retornos mensuales (WIDE format)\n",
        "log_returns_monthly = pd.read_parquet(f'{DATA_PROCESSED_DIR}/log_returns_monthly.parquet')\n",
        "\n",
        "# Cargar eligibility mask\n",
        "eligibility_mask = pd.read_parquet(f'{DATA_PROCESSED_DIR}/eligibility_mask.parquet')\n",
        "\n",
        "# Cargar fechas de rebalanceo\n",
        "rebalance_dates = pd.read_csv(f'{DATA_PROCESSED_DIR}/rebalance_dates.csv', \n",
        "                               parse_dates=['date'])['date']\n",
        "\n",
        "# Alinear retornos con fechas de rebalanceo\n",
        "returns_mc = log_returns_monthly.reindex(rebalance_dates)\n",
        "eligibility_mc = eligibility_mask.reindex(rebalance_dates)\n",
        "\n",
        "print(f\"Retornos para MC: {returns_mc.shape}\")\n",
        "print(f\"Eligibility mask: {eligibility_mc.shape}\")\n",
        "print(f\"Fechas rebalanceo: {len(rebalance_dates)}\")\n",
        "print(f\"\\n✓ Datos cargados correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Pre-cálculo de Índices Elegibles {#pre-calculo}\n",
        "\n",
        "Pre-cálculo de índices elegibles por mes para optimizar el acceso durante la simulación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "PRE-CALCULANDO ÍNDICES ELEGIBLES\n",
            "======================================================================\n",
            "✓ Índices pre-calculados para 133 meses\n",
            "  Rango de elegibles por mes: 497 - 506\n"
          ]
        }
      ],
      "source": [
        "# Convertir a arrays numpy\n",
        "retornos_array = returns_mc.values  # (n_meses, n_tickers)\n",
        "elegibles_array = eligibility_mc.values  # (n_meses, n_tickers) boolean\n",
        "\n",
        "n_meses = retornos_array.shape[0]\n",
        "n_tickers = retornos_array.shape[1]\n",
        "\n",
        "# Pre-calcular índices elegibles por mes\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PRE-CALCULANDO ÍNDICES ELEGIBLES\")\n",
        "print(\"=\"*70)\n",
        "indices_elegibles_por_mes = []\n",
        "n_elegibles_por_mes = []\n",
        "for mes_idx in range(n_meses):\n",
        "    elegibles_mes = elegibles_array[mes_idx]\n",
        "    indices_elegibles = np.where(elegibles_mes)[0]\n",
        "    indices_elegibles_por_mes.append(indices_elegibles)\n",
        "    n_elegibles_por_mes.append(len(indices_elegibles))\n",
        "print(f\"✓ Índices pre-calculados para {n_meses} meses\")\n",
        "print(f\"  Rango de elegibles por mes: {min(n_elegibles_por_mes)} - {max(n_elegibles_por_mes)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Monte Carlo con Vectorización Completa Optimizada {#monte-carlo}\n",
        "\n",
        "Esta sección implementa el test de Monte Carlo con **optimizaciones críticas** que eliminan redundancias y maximizan la velocidad.\n",
        "\n",
        "### Optimizaciones Aplicadas:\n",
        "\n",
        "1. **Extracción directa de retornos con índices**: \n",
        "   - Usa `retornos_array[mes_idx, indices_seleccionados]` para extraer solo los retornos necesarios\n",
        "   - Shape: `(n_monos × 20)` - solo los retornos que se necesitan, sin ceros\n",
        "   - Evita construir matriz completa de pesos `(n_monos × n_assets)` con mayoría de ceros\n",
        "\n",
        "2. **Cálculo de promedio equiponderado con `np.mean()`**:\n",
        "   - `np.mean(retornos_seleccionados, axis=1)` es matemáticamente equivalente a multiplicación de matrices con pesos equiponderados\n",
        "   - Porque: `mean = sum/20 = sum × 0.05` (equivalente a pesos de 5% cada uno)\n",
        "   - Más eficiente que: `(1 × 845) @ (845 × 50,000)` con mayoría de ceros\n",
        "\n",
        "3. **Selección aleatoria vectorizada mes a mes**:\n",
        "   - Genera selecciones cuando se necesitan (no pre-calcula para todos los meses)\n",
        "   - Usa `np.argsort` sobre matriz aleatoria `(n_monos × n_elegibles)`\n",
        "   - Sin loops sobre monos\n",
        "\n",
        "4. **Cálculo acumulado vectorizado**:\n",
        "   - Usa `np.sum` sobre todos los monos simultáneamente\n",
        "   - Sin loops sobre monos\n",
        "\n",
        "### Estrategia de Implementación:\n",
        "\n",
        "- **Generar selecciones mes a mes** cuando se necesiten (no pre-calcular)\n",
        "- **Extraer retornos directamente** usando advanced indexing: solo `(n_monos × 20)` elementos\n",
        "- **Calcular promedio equiponderado** con `np.mean()` en lugar de multiplicación de matrices\n",
        "- **Sin loops sobre monos**, solo loop sobre meses (necesario por eligibility_mask variable)\n",
        "\n",
        "### Ventajas de esta Optimización:\n",
        "\n",
        "- **Memoria**: Reduce de ~42M elementos (50,000 × 845) a ~1M elementos (50,000 × 20) por mes\n",
        "- **Velocidad**: Elimina construcción de matrices grandes y multiplicaciones ineficientes\n",
        "- **Eficiencia**: Trabaja solo con los datos necesarios (2.4% útil vs 100% de ceros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CONFIGURACIÓN MONTE CARLO (VECTORIZACIÓN COMPLETA)\n",
            "======================================================================\n",
            "Simulaciones: 25,000,000\n",
            "Batch size: 50,000\n",
            "Activos por cartera: 20\n",
            "Peso por activo: 5.0% (equiponderado)\n",
            "Rebalanceo: FULL REBALANCE cada mes (vender todo, comprar todo)\n",
            "Coste rebalanceo: 0.46% (0.23% venta + 0.23% compra)\n",
            "Requisito: < 24 horas\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Monte Carlo con Vectorización Completa Optimizada\n",
        "\n",
        "Cada mono:\n",
        "1. Vende TODA su posición (100%) cada mes (full rebalance)\n",
        "2. Compra 20 activos ALEATORIOS de los ELEGIBLES ese mes\n",
        "3. Usa mismo universo que la estrategia (fair comparison)\n",
        "4. Paga 0.46% por rebalanceo (0.23% venta + 0.23% compra)\n",
        "\n",
        "OPTIMIZACIONES CRÍTICAS APLICADAS:\n",
        "- Extracción directa de retornos con índices (solo n_monos × 20 elementos)\n",
        "- Cálculo de promedio equiponderado con np.mean() (equivalente a multiplicación de matrices)\n",
        "- Selección aleatoria vectorizada mes a mes (sin pre-cálculo innecesario)\n",
        "- Sin construcción de matriz completa de pesos (evita 42M elementos con mayoría de ceros)\n",
        "- Cálculo acumulado vectorizado (sin loops sobre monos)\n",
        "\"\"\"\n",
        "\n",
        "# Configuración\n",
        "N_SIMULACIONES = 25_000_000\n",
        "BATCH_SIZE = 50_000  # Batch grande para máxima vectorización\n",
        "N_ACTIVOS_SELECCION = 20\n",
        "PESO_POR_ACTIVO = 1.0 / N_ACTIVOS_SELECCION  # 5% = 0.05 (equiponderado)\n",
        "COSTE_REBALANCEO = 0.0046  # 0.46% = 0.23% venta + 0.23% compra (full rebalance cada mes)\n",
        "PROGRESS_INTERVAL = 25_000  # Avisar cada 0.1% (25,000 de 25M)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CONFIGURACIÓN MONTE CARLO (VECTORIZACIÓN COMPLETA)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Simulaciones: {N_SIMULACIONES:,}\")\n",
        "print(f\"Batch size: {BATCH_SIZE:,}\")\n",
        "print(f\"Activos por cartera: {N_ACTIVOS_SELECCION}\")\n",
        "print(f\"Peso por activo: {PESO_POR_ACTIVO*100:.1f}% (equiponderado)\")\n",
        "print(f\"Rebalanceo: FULL REBALANCE cada mes (vender todo, comprar todo)\")\n",
        "print(f\"Coste rebalanceo: {COSTE_REBALANCEO*100:.2f}% (0.23% venta + 0.23% compra)\")\n",
        "print(f\"Requisito: < 24 horas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "INICIANDO MONTE CARLO CON VECTORIZACIÓN COMPLETA OPTIMIZADA\n",
            "Simulaciones: 25,000,000\n",
            "Batch size: 50,000\n",
            "======================================================================\n",
            "\n",
            "Iniciando procesamiento de 500 batches (batch_size=50,000)...\n",
            "Progress cada 0.1% (25,000 simulaciones)\n",
            "\n",
            "OPTIMIZACIONES APLICADAS:\n",
            "  - Extracción directa de retornos (solo n_monos × 20 elementos)\n",
            "  - np.mean() en lugar de multiplicación de matrices (equivalente matemático)\n",
            "  - Sin construcción de matriz completa de pesos (evita 42M elementos con ceros)\n",
            "  - Selecciones generadas mes a mes (sin pre-cálculo innecesario)\n",
            "\n",
            "Progreso:  0.20% (50,000 / 25,000,000 simulaciones) | Velocidad: 317 sim/s | Tiempo: 157.8s\n",
            "Progreso:  0.40% (100,000 / 25,000,000 simulaciones) | Velocidad: 311 sim/s | Tiempo: 321.8s\n",
            "Progreso:  0.60% (150,000 / 25,000,000 simulaciones) | Velocidad: 315 sim/s | Tiempo: 475.9s\n",
            "Progreso:  0.80% (200,000 / 25,000,000 simulaciones) | Velocidad: 307 sim/s | Tiempo: 650.8s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m rand_matrix = rng.random((n_monos_batch, n_elegibles))\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Usar argsort para obtener top 20 índices por fila (vectorizado)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m indices_permutados = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrand_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Seleccionar top 20: (n_monos × 20)\u001b[39;00m\n\u001b[32m     69\u001b[39m indices_seleccionados = indices_elegibles[indices_permutados[:, :N_ACTIVOS_SELECCION]]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oscar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1242\u001b[39m, in \u001b[36margsort\u001b[39m\u001b[34m(a, axis, kind, order, stable)\u001b[39m\n\u001b[32m   1129\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34margsort\u001b[39m(a, axis=-\u001b[32m1\u001b[39m, kind=\u001b[38;5;28;01mNone\u001b[39;00m, order=\u001b[38;5;28;01mNone\u001b[39;00m, *, stable=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1132\u001b[39m \u001b[33;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[32m   1133\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1240\u001b[39m \n\u001b[32m   1241\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margsort\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstable\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oscar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INICIANDO MONTE CARLO CON VECTORIZACIÓN COMPLETA OPTIMIZADA\")\n",
        "print(f\"Simulaciones: {N_SIMULACIONES:,}\")\n",
        "print(f\"Batch size: {BATCH_SIZE:,}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Verificar que los datos estén cargados\n",
        "try:\n",
        "    returns_mc\n",
        "    eligibility_mc\n",
        "except NameError:\n",
        "    raise NameError(\"ERROR: Ejecuta primero las celdas anteriores que cargan los datos\")\n",
        "\n",
        "# Pre-calcular constantes\n",
        "años = n_meses / 12.0\n",
        "factor_cagr = 1 / años\n",
        "\n",
        "# Array de resultados\n",
        "resultados_cagr = np.zeros(N_SIMULACIONES, dtype=np.float32)\n",
        "\n",
        "# Crear generador de números aleatorios optimizado\n",
        "rng = np.random.default_rng()\n",
        "\n",
        "# Calcular número de batches\n",
        "n_batches = N_SIMULACIONES // BATCH_SIZE\n",
        "\n",
        "print(f\"\\nIniciando procesamiento de {n_batches} batches (batch_size={BATCH_SIZE:,})...\")\n",
        "print(f\"Progress cada 0.1% ({PROGRESS_INTERVAL:,} simulaciones)\\n\")\n",
        "print(\"OPTIMIZACIONES APLICADAS:\")\n",
        "print(\"  - Extracción directa de retornos (solo n_monos × 20 elementos)\")\n",
        "print(\"  - np.mean() en lugar de multiplicación de matrices (equivalente matemático)\")\n",
        "print(\"  - Sin construcción de matriz completa de pesos (evita 42M elementos con ceros)\")\n",
        "print(\"  - Selecciones generadas mes a mes (sin pre-cálculo innecesario)\\n\")\n",
        "\n",
        "# Iniciar timer\n",
        "start_time = time.time()\n",
        "\n",
        "# ========== LOOP SOBRE BATCHES (OPTIMIZADO) ==========\n",
        "for batch_idx in range(n_batches):\n",
        "    \n",
        "    n_monos_batch = BATCH_SIZE if batch_idx < n_batches - 1 else N_SIMULACIONES - (batch_idx * BATCH_SIZE)\n",
        "    \n",
        "    # Retornos acumulados para este batch: (n_monos,)\n",
        "    retornos_acumulados = np.zeros(n_monos_batch, dtype=np.float32)\n",
        "    \n",
        "    # ========== PROCESAR MES A MES (sin pre-calcular selecciones) ==========\n",
        "    for mes_idx in range(n_meses):\n",
        "        indices_elegibles = indices_elegibles_por_mes[mes_idx]\n",
        "        n_elegibles = n_elegibles_por_mes[mes_idx]\n",
        "        \n",
        "        if n_elegibles < N_ACTIVOS_SELECCION:\n",
        "            # Caso borde: menos elegibles que necesarios\n",
        "            if batch_idx == 0 and mes_idx == 0:\n",
        "                print(f\"ADVERTENCIA: Mes {mes_idx}, solo {n_elegibles} elegibles\")\n",
        "            if n_elegibles == 0:\n",
        "                # No hay elegibles, retorno = 0 para este mes\n",
        "                continue\n",
        "            # Repetir los elegibles disponibles\n",
        "            indices_seleccionados = np.tile(indices_elegibles, (n_monos_batch, 1))[:, :N_ACTIVOS_SELECCION]\n",
        "        else:\n",
        "            # ========== OPTIMIZACIÓN 1: Generar selecciones aleatorias (vectorizado) ==========\n",
        "            # Generar matriz aleatoria: (n_monos × n_elegibles)\n",
        "            rand_matrix = rng.random((n_monos_batch, n_elegibles))\n",
        "            \n",
        "            # Usar argsort para obtener top 20 índices por fila (vectorizado)\n",
        "            indices_permutados = np.argsort(rand_matrix, axis=1)\n",
        "            \n",
        "            # Seleccionar top 20: (n_monos × 20)\n",
        "            indices_seleccionados = indices_elegibles[indices_permutados[:, :N_ACTIVOS_SELECCION]]\n",
        "        \n",
        "        # ========== OPTIMIZACIÓN 2: Extraer retornos directamente usando índices ==========\n",
        "        # Extraer retornos de los 20 activos seleccionados para cada mono\n",
        "        # Shape: (n_monos × 20) - solo los retornos que necesitas, sin ceros\n",
        "        # NOTA: Esto es mucho más eficiente que construir matriz completa de pesos\n",
        "        # (n_monos × n_assets) con mayoría de ceros y luego multiplicar matrices\n",
        "        retornos_seleccionados = retornos_array[mes_idx, indices_seleccionados]\n",
        "        \n",
        "        # ========== OPTIMIZACIÓN 3: Calcular promedio equiponderado (equivalente a multiplicación de matrices) ==========\n",
        "        # np.mean sobre axis=1 es matemáticamente equivalente a: sum(retornos × 0.05) para equiponderado\n",
        "        # Porque: mean = sum/20 = sum × 0.05 (equivalente a pesos de 5% cada uno)\n",
        "        # Esto evita construir matriz (n_monos × n_assets) con 42M elementos (solo 2.4% útiles)\n",
        "        # y multiplicar (1 × 845) @ (845 × 50,000) cuando solo necesitamos trabajar con 20 activos\n",
        "        retorno_mes_monos = np.mean(retornos_seleccionados, axis=1)\n",
        "        # Shape: (n_monos,) - retorno promedio de los 20 activos para cada mono\n",
        "        \n",
        "        # ========== Aplicar coste de rebalanceo vectorizado ==========\n",
        "        retorno_neto = retorno_mes_monos - COSTE_REBALANCEO\n",
        "        \n",
        "        # ========== Acumular retornos vectorizado ==========\n",
        "        retornos_acumulados += retorno_neto\n",
        "    \n",
        "    # ========== CALCULAR CAGR VECTORIZADO ==========\n",
        "    # Convertir a CAGR anualizado\n",
        "    cagr_batch = (np.exp(retornos_acumulados) ** factor_cagr) - 1\n",
        "    \n",
        "    # Guardar resultados\n",
        "    start_idx = batch_idx * BATCH_SIZE\n",
        "    end_idx = min(start_idx + BATCH_SIZE, N_SIMULACIONES)\n",
        "    resultados_cagr[start_idx:end_idx] = cagr_batch[:end_idx-start_idx]\n",
        "    \n",
        "    # Progress report\n",
        "    simulaciones_procesadas = (batch_idx + 1) * BATCH_SIZE\n",
        "    if simulaciones_procesadas % PROGRESS_INTERVAL == 0 or (batch_idx + 1) == n_batches:\n",
        "        pct_completo = (simulaciones_procesadas / N_SIMULACIONES) * 100\n",
        "        elapsed = time.time() - start_time\n",
        "        rate = simulaciones_procesadas / elapsed if elapsed > 0 else 0\n",
        "        print(f\"Progreso: {pct_completo:>5.2f}% ({simulaciones_procesadas:,} / {N_SIMULACIONES:,} simulaciones) | \"\n",
        "              f\"Velocidad: {rate:,.0f} sim/s | Tiempo: {elapsed:.1f}s\")\n",
        "\n",
        "elapsed_total = time.time() - start_time\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"MONTE CARLO COMPLETADO\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Total simulaciones: {N_SIMULACIONES:,}\")\n",
        "print(f\"Batches procesados: {n_batches}\")\n",
        "print(f\"Tiempo total: {elapsed_total:.2f} segundos ({elapsed_total/60:.2f} minutos)\")\n",
        "print(f\"Velocidad promedio: {N_SIMULACIONES/elapsed_total:,.0f} simulaciones/segundo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Análisis de Resultados {#resultados}\n",
        "\n",
        "Análisis de los resultados de la simulación de Monte Carlo y comparación con la estrategia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular métricas de la estrategia (para comparación)\n",
        "def calcular_metricas(equity_curve, retornos_mensuales, risk_free_rate=0.02):\n",
        "    \"\"\"Calcula métricas financieras básicas.\"\"\"\n",
        "    retornos = retornos_mensuales.dropna()\n",
        "    años = (equity_curve.index[-1] - equity_curve.index[0]).days / 365.25\n",
        "    total_return = (equity_curve.iloc[-1] / equity_curve.iloc[0]) - 1\n",
        "    cagr = ((1 + total_return) ** (1 / años) - 1) * 100 if años > 0 else 0\n",
        "    return cagr\n",
        "\n",
        "# Calcular CAGR de la estrategia\n",
        "cagr_estrategia = calcular_metricas(df_equity['equity'], df_equity['retorno_mensual']) / 100  # Convertir de % a decimal\n",
        "\n",
        "# Comparar con estrategia\n",
        "percentil = (resultados_cagr < cagr_estrategia).sum() / N_SIMULACIONES * 100\n",
        "\n",
        "# Estadísticas\n",
        "media_monos = resultados_cagr.mean()\n",
        "mediana_monos = np.median(resultados_cagr)\n",
        "std_monos = resultados_cagr.std()\n",
        "p95 = np.percentile(resultados_cagr, 95)\n",
        "p99 = np.percentile(resultados_cagr, 99)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"RESULTADOS MONTE CARLO\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Media monos:      {media_monos*100:.2f}%\")\n",
        "print(f\"Mediana monos:    {mediana_monos*100:.2f}%\")\n",
        "print(f\"Std monos:        {std_monos*100:.2f}%\")\n",
        "print(f\"Percentil 95:     {p95*100:.2f}%\")\n",
        "print(f\"Percentil 99:     {p99*100:.2f}%\")\n",
        "print(f\"\\nEstrategia:       {cagr_estrategia*100:.2f}%\")\n",
        "print(f\"Percentil:        {percentil:.2f}%\")\n",
        "print(f\"\\n¿Supera monos?    {'SÍ ✓' if percentil > 50 else 'NO ✗'}\")\n",
        "\n",
        "# Validaciones\n",
        "assert resultados_cagr.min() > -0.9, \"CAGR mínimo fuera de rango\"\n",
        "assert resultados_cagr.max() < 3.0, \"CAGR máximo fuera de rango\"\n",
        "assert not np.isnan(resultados_cagr).any(), \"NaN detectados\"\n",
        "assert not np.isinf(resultados_cagr).any(), \"Inf detectados\"\n",
        "\n",
        "print(\"\\n✓ Todas las validaciones pasadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualización\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "ax.hist(resultados_cagr * 100, bins=150, alpha=0.7, edgecolor='black', color='steelblue')\n",
        "ax.axvline(cagr_estrategia * 100, color='red', linewidth=3,\n",
        "           label=f'Estrategia: {cagr_estrategia*100:.2f}% (P{percentil:.1f})')\n",
        "ax.axvline(media_monos * 100, color='orange', linewidth=2, linestyle='--',\n",
        "           label=f'Media Monos: {media_monos*100:.2f}%')\n",
        "ax.set_xlabel('CAGR (%)')\n",
        "ax.set_ylabel('Frecuencia')\n",
        "ax.set_title(f'Distribución de {N_SIMULACIONES:,} Portfolios Aleatorios (Vectorización Completa)')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Comparación de Velocidad y Análisis Teórico {#comparacion}\n",
        "\n",
        "### Comparación con Notebook 6\n",
        "\n",
        "**Notebook 6 (Optimizado):**\n",
        "- Vectorización de selección aleatoria con argsort\n",
        "- Batch size: 50,000\n",
        "- Loop sobre meses dentro de cada batch\n",
        "- Cálculo de retornos usando indexing avanzado sobre array 3D\n",
        "\n",
        "**Notebook 7 (Vectorización Completa Optimizada):**\n",
        "- Extracción directa de retornos: `retornos_array[mes_idx, indices_seleccionados]` → `(n_monos × 20)`\n",
        "- Cálculo de promedio equiponderado con `np.mean()` (equivalente matemático a multiplicación de matrices)\n",
        "- Sin construcción de matriz completa de pesos (evita 42M elementos con mayoría de ceros)\n",
        "- Selecciones generadas mes a mes (sin pre-cálculo innecesario)\n",
        "\n",
        "### Optimizaciones Aplicadas y Justificación:\n",
        "\n",
        "1. **Eliminación de matriz completa de pesos**:\n",
        "   - **Antes**: Construía `weights_mes = np.zeros((50,000 × 845))` = 42,250,000 elementos\n",
        "   - **Ahora**: Extrae directamente `(50,000 × 20)` = 1,000,000 elementos\n",
        "   - **Reducción**: 97.6% menos memoria (solo 2.4% útil vs 100% de ceros)\n",
        "\n",
        "2. **Equivalencia matemática de `np.mean()`**:\n",
        "   - **Equiponderado**: Cada activo tiene peso 5% = 0.05\n",
        "   - **Multiplicación de matrices**: `sum(retornos × 0.05)` para cada mono\n",
        "   - **np.mean()**: `sum(retornos) / 20 = sum(retornos) × 0.05` (mismo resultado)\n",
        "   - **Ventaja**: Más eficiente, trabaja solo con datos necesarios\n",
        "\n",
        "3. **Eliminación de pre-cálculo de selecciones**:\n",
        "   - **Antes**: Pre-calculaba todas las selecciones para todos los meses antes de calcular retornos\n",
        "   - **Ahora**: Genera selecciones mes a mes cuando se necesitan\n",
        "   - **Ventaja**: Reduce memoria y tiempo innecesario\n",
        "\n",
        "4. **Extracción directa vs Multiplicación de matrices**:\n",
        "   - **Antes**: `(1 × 845) @ (845 × 50,000)` con mayoría de ceros\n",
        "   - **Ahora**: Extracción directa `(50,000 × 20)` y `np.mean(axis=1)`\n",
        "   - **Ventaja**: Trabaja solo con datos relevantes, más rápido\n",
        "\n",
        "### Ventajas de la Optimización:\n",
        "\n",
        "1. **Memoria reducida**: De ~42M elementos a ~1M elementos por mes (97.6% reducción)\n",
        "2. **Velocidad mejorada**: Elimina construcción de matrices grandes y multiplicaciones ineficientes\n",
        "3. **Eficiencia**: Trabaja solo con los datos necesarios (20 activos vs 845 activos)\n",
        "4. **Mismo resultado**: Matemáticamente equivalente, solo más eficiente\n",
        "\n",
        "### Limitaciones:\n",
        "\n",
        "- **Loop sobre meses**: Necesario por eligibility_mask variable mes a mes\n",
        "- **Trade-off**: Optimización de memoria y velocidad manteniendo restricciones del problema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análisis de memoria y eficiencia\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ANÁLISIS DE EFICIENCIA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Estimar memoria usada\n",
        "BYTES_PER_FLOAT32 = 4\n",
        "BYTES_PER_INT32 = 4\n",
        "GB = 1024**3\n",
        "\n",
        "# Memoria por batch (OPTIMIZADA - sin matriz completa de pesos)\n",
        "mem_retornos_seleccionados = (BATCH_SIZE * N_ACTIVOS_SELECCION * BYTES_PER_FLOAT32) / GB  # Solo 20 activos\n",
        "mem_selecciones = (BATCH_SIZE * N_ACTIVOS_SELECCION * BYTES_PER_INT32) / GB  # int32 para índices\n",
        "mem_retornos_acumulados = (BATCH_SIZE * BYTES_PER_FLOAT32) / GB\n",
        "mem_total_batch = mem_retornos_seleccionados + mem_selecciones + mem_retornos_acumulados\n",
        "\n",
        "# Comparación con enfoque anterior (matriz completa de pesos)\n",
        "mem_weights_anterior = (BATCH_SIZE * n_tickers * BYTES_PER_FLOAT32) / GB  # 50,000 × 845\n",
        "reduccion_memoria = (1 - mem_total_batch / mem_weights_anterior) * 100\n",
        "\n",
        "print(f\"\\nMemoria por batch (OPTIMIZADA):\")\n",
        "print(f\"  Retornos seleccionados (n_monos × 20): {mem_retornos_seleccionados*1000:.2f} MB\")\n",
        "print(f\"  Selecciones (índices): {mem_selecciones*1000:.2f} MB\")\n",
        "print(f\"  Retornos acumulados: {mem_retornos_acumulados*1000:.2f} MB\")\n",
        "print(f\"  Total: {mem_total_batch*1000:.2f} MB\")\n",
        "\n",
        "print(f\"\\nComparación con enfoque anterior:\")\n",
        "print(f\"  Matriz completa de pesos (n_monos × n_assets): {mem_weights_anterior*1000:.2f} MB\")\n",
        "print(f\"  Reducción de memoria: {reduccion_memoria:.1f}%\")\n",
        "print(f\"  Eficiencia: Solo trabajamos con {N_ACTIVOS_SELECCION}/{n_tickers} = {(N_ACTIVOS_SELECCION/n_tickers*100):.1f}% de los activos\")\n",
        "\n",
        "print(f\"\\nMemoria total (resultados):\")\n",
        "mem_resultados = (N_SIMULACIONES * BYTES_PER_FLOAT32) / GB\n",
        "print(f\"  Resultados CAGR: {mem_resultados*1000:.2f} MB\")\n",
        "\n",
        "print(f\"\\nVelocidad de procesamiento:\")\n",
        "print(f\"  Tiempo total: {elapsed_total:.2f} segundos ({elapsed_total/60:.2f} minutos)\")\n",
        "print(f\"  Velocidad: {N_SIMULACIONES/elapsed_total:,.0f} simulaciones/segundo\")\n",
        "print(f\"  Tiempo por batch: {elapsed_total/n_batches:.2f} segundos\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"NOTEBOOK 7 COMPLETADO (OPTIMIZADO)\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nEste notebook demuestra cómo optimizaciones críticas pueden mejorar\")\n",
        "print(\"significativamente la velocidad y eficiencia de memoria de la simulación\")\n",
        "print(\"de Monte Carlo, manteniendo las mismas restricciones (eligibility_mask,\")\n",
        "print(\"rebalanceo mensual) y resultados matemáticamente equivalentes al Notebook 6.\")\n",
        "print(\"\\nOPTIMIZACIONES CLAVE:\")\n",
        "print(\"  ✓ Extracción directa de retornos (solo n_monos × 20 elementos)\")\n",
        "print(\"  ✓ np.mean() en lugar de multiplicación de matrices (equivalente matemático)\")\n",
        "print(\"  ✓ Sin construcción de matriz completa de pesos (97.6% reducción de memoria)\")\n",
        "print(\"  ✓ Selecciones generadas mes a mes (sin pre-cálculo innecesario)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
