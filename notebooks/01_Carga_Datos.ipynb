{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 1: Carga de Datos\n",
        "\n",
        "## Objetivo\n",
        "Este notebook se encarga de la ingesta inicial de datos históricos de precios, validación básica de calidad y definición del universo de inversión según las especificaciones del proyecto.\n",
        "\n",
        "## Índice\n",
        "1. [Configuración del Entorno](#configuracion)\n",
        "2. [Carga de Datos Históricos](#carga-datos)\n",
        "3. [Validación y Limpieza Inicial](#validacion)\n",
        "4. [Definición del Universo de Inversión](#universo)\n",
        "5. [Guardado de Datos Preparados](#guardado)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuración del Entorno {#configuracion}\n",
        "\n",
        "Importación de librerías permitidas y configuración inicial del entorno de trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librerías permitidas según especificaciones\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# Configuración\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Configuración de pandas para mejor visualización\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "\n",
        "print(\"Librerías importadas correctamente\")\n",
        "print(f\"Fecha de ejecución: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carga de Datos Históricos {#carga-datos}\n",
        "\n",
        "Carga del archivo histórico de precios desde Google Drive o fuente local.\n",
        "\n",
        "**Nota:** Según el PDF, el histórico está disponible en:\n",
        "https://drive.google.com/file/d/1nvubXdAu0EONlrP_yrURZbnPhBQ-uDaB/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_price_data(file_path=None, use_yfinance=False, symbols=None, start_date='2014-01-01'):\n",
        "    \"\"\"\n",
        "    Carga datos históricos de precios.\n",
        "    \n",
        "    Parámetros:\n",
        "    -----------\n",
        "    file_path : str, optional\n",
        "        Ruta al archivo local (CSV, Parquet, etc.)\n",
        "    use_yfinance : bool\n",
        "        Si True, descarga datos usando yfinance\n",
        "    symbols : list, optional\n",
        "        Lista de símbolos a descargar (si use_yfinance=True)\n",
        "    start_date : str\n",
        "        Fecha de inicio para descarga (formato 'YYYY-MM-DD')\n",
        "    \n",
        "    Retorna:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        DataFrame con precios históricos (índice: fecha, columnas: símbolos)\n",
        "    \"\"\"\n",
        "    if file_path and os.path.exists(file_path):\n",
        "        # Carga desde archivo local\n",
        "        if file_path.endswith('.parquet'):\n",
        "            df = pd.read_parquet(file_path)\n",
        "        elif file_path.endswith('.csv'):\n",
        "            df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
        "        else:\n",
        "            raise ValueError(f\"Formato no soportado: {file_path}\")\n",
        "        print(f\"Datos cargados desde: {file_path}\")\n",
        "        \n",
        "    elif use_yfinance and symbols:\n",
        "        # Descarga usando yfinance\n",
        "        print(f\"Descargando datos para {len(symbols)} símbolos desde {start_date}...\")\n",
        "        data_dict = {}\n",
        "        for symbol in symbols:\n",
        "            try:\n",
        "                ticker = yf.Ticker(symbol)\n",
        "                hist = ticker.history(start=start_date)\n",
        "                if not hist.empty:\n",
        "                    data_dict[symbol] = hist['Close']\n",
        "                    print(f\"  ✓ {symbol}: {len(hist)} días\")\n",
        "                else:\n",
        "                    print(f\"  ✗ {symbol}: Sin datos\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ✗ {symbol}: Error - {str(e)}\")\n",
        "        \n",
        "        df = pd.DataFrame(data_dict)\n",
        "        print(f\"\\nTotal de símbolos cargados: {len(df.columns)}\")\n",
        "    else:\n",
        "        raise ValueError(\"Debe proporcionar file_path o usar use_yfinance=True con symbols\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "# CARGAR DATOS AQUÍ\n",
        "# Opción 1: Desde archivo local (ajustar ruta según tu caso)\n",
        "# price_data = load_price_data(file_path='../data/historical_prices.parquet')\n",
        "\n",
        "# Opción 2: Desde Google Drive (descargar manualmente primero)\n",
        "# price_data = load_price_data(file_path='../data/historical_prices.csv')\n",
        "\n",
        "# Opción 3: Usando yfinance (solo para pruebas, no recomendado para todo el universo)\n",
        "# symbols_sp500 = ['SPY', 'AAPL', 'MSFT', ...]  # Lista completa del S&P 500\n",
        "# price_data = load_price_data(use_yfinance=True, symbols=symbols_sp500, start_date='2014-01-01')\n",
        "\n",
        "# EJEMPLO: Cargar datos (REEMPLAZAR CON TU MÉTODO)\n",
        "print(\"\\n⚠️  IMPORTANTE: Reemplazar esta celda con la carga real de datos\")\n",
        "print(\"El archivo debe contener precios de cierre diarios del S&P 500 desde 2014\")\n",
        "\n",
        "# Estructura esperada del DataFrame:\n",
        "# - Índice: fechas (datetime)\n",
        "# - Columnas: símbolos de activos (ej: 'AAPL', 'MSFT', 'SPY', etc.)\n",
        "# - Valores: precios de cierre (float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Validación y Limpieza Inicial {#validacion}\n",
        "\n",
        "Validación de calidad de datos: fechas, valores faltantes, duplicados y coherencia temporal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_price_data(df, min_date='2014-01-01'):\n",
        "    \"\"\"\n",
        "    Valida y limpia datos de precios.\n",
        "    \n",
        "    Parámetros:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame con precios históricos\n",
        "    min_date : str\n",
        "        Fecha mínima requerida\n",
        "    \n",
        "    Retorna:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        DataFrame validado y limpio\n",
        "    dict\n",
        "        Diccionario con estadísticas de validación\n",
        "    \"\"\"\n",
        "    validation_stats = {\n",
        "        'fecha_inicio': None,\n",
        "        'fecha_fin': None,\n",
        "        'total_dias': 0,\n",
        "        'total_activos': 0,\n",
        "        'activos_con_datos': 0,\n",
        "        'valores_faltantes_pct': 0.0,\n",
        "        'duplicados': 0,\n",
        "        'valores_negativos': 0\n",
        "    }\n",
        "    \n",
        "    # Validar índice de fechas\n",
        "    if not isinstance(df.index, pd.DatetimeIndex):\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "    \n",
        "    df = df.sort_index()\n",
        "    \n",
        "    # Estadísticas básicas\n",
        "    validation_stats['fecha_inicio'] = df.index.min()\n",
        "    validation_stats['fecha_fin'] = df.index.max()\n",
        "    validation_stats['total_dias'] = len(df)\n",
        "    validation_stats['total_activos'] = len(df.columns)\n",
        "    \n",
        "    # Validar fechas mínimas\n",
        "    if validation_stats['fecha_inicio'] > pd.to_datetime(min_date):\n",
        "        warnings.warn(f\"Los datos comienzan en {validation_stats['fecha_inicio']}, se requiere desde {min_date}\")\n",
        "    \n",
        "    # Detectar duplicados\n",
        "    validation_stats['duplicados'] = df.index.duplicated().sum()\n",
        "    if validation_stats['duplicados'] > 0:\n",
        "        df = df[~df.index.duplicated(keep='first')]\n",
        "        print(f\"⚠️  Eliminados {validation_stats['duplicados']} días duplicados\")\n",
        "    \n",
        "    # Validar valores\n",
        "    validation_stats['valores_negativos'] = (df < 0).sum().sum()\n",
        "    if validation_stats['valores_negativos'] > 0:\n",
        "        print(f\"⚠️  Detectados {validation_stats['valores_negativos']} valores negativos\")\n",
        "    \n",
        "    # Estadísticas de valores faltantes\n",
        "    missing_pct = (df.isna().sum() / len(df) * 100).sort_values(ascending=False)\n",
        "    validation_stats['valores_faltantes_pct'] = df.isna().sum().sum() / (len(df) * len(df.columns)) * 100\n",
        "    \n",
        "    # Activos con datos suficientes\n",
        "    validation_stats['activos_con_datos'] = (missing_pct < 50).sum()\n",
        "    \n",
        "    return df, validation_stats\n",
        "\n",
        "\n",
        "# Ejecutar validación (descomentar cuando price_data esté cargado)\n",
        "# price_data_clean, validation_stats = validate_price_data(price_data, min_date='2014-01-01')\n",
        "\n",
        "# Mostrar estadísticas\n",
        "# print(\"\\n=== ESTADÍSTICAS DE VALIDACIÓN ===\")\n",
        "# for key, value in validation_stats.items():\n",
        "#     print(f\"{key}: {value}\")\n",
        "\n",
        "# print(\"\\n=== PRIMERAS FILAS ===\")\n",
        "# print(price_data_clean.head())\n",
        "\n",
        "# print(\"\\n=== ÚLTIMAS FILAS ===\")\n",
        "# print(price_data_clean.tail())\n",
        "\n",
        "print(\"⚠️  Ejecutar validación después de cargar price_data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def define_investment_universe(df, lookback_months=13, min_trading_days=0.8):\n",
        "    \"\"\"\n",
        "    Define el universo de inversión para cada mes.\n",
        "    \n",
        "    Criterios:\n",
        "    - Activos que forman parte del S&P 500 durante últimos 13 meses\n",
        "    - Mínimo de días de cotización (para evitar activos con muchos faltantes)\n",
        "    \n",
        "    Parámetros:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame con precios históricos\n",
        "    lookback_months : int\n",
        "        Meses hacia atrás para considerar activo elegible\n",
        "    min_trading_days : float\n",
        "        Proporción mínima de días con datos (0.8 = 80%)\n",
        "    \n",
        "    Retorna:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        DataFrame con universo mensual (índice: fecha, columnas: activos elegibles)\n",
        "    \"\"\"\n",
        "    # Resample a mensual (último día hábil del mes)\n",
        "    monthly_prices = df.resample('M').last()\n",
        "    \n",
        "    # Para cada mes, determinar activos elegibles\n",
        "    universe_dict = {}\n",
        "    \n",
        "    for date in monthly_prices.index:\n",
        "        # Ventana de lookback\n",
        "        start_date = date - pd.DateOffset(months=lookback_months)\n",
        "        window_data = df.loc[start_date:date]\n",
        "        \n",
        "        # Calcular proporción de datos disponibles por activo\n",
        "        data_availability = (window_data.notna().sum() / len(window_data))\n",
        "        \n",
        "        # Filtrar activos con suficiente disponibilidad\n",
        "        eligible_assets = data_availability[data_availability >= min_trading_days].index.tolist()\n",
        "        \n",
        "        universe_dict[date] = eligible_assets\n",
        "    \n",
        "    # Crear DataFrame con universo mensual\n",
        "    universe_df = pd.DataFrame.from_dict(universe_dict, orient='index')\n",
        "    universe_df.index.name = 'fecha'\n",
        "    \n",
        "    return universe_df, monthly_prices\n",
        "\n",
        "\n",
        "# Ejecutar definición de universo (descomentar cuando price_data_clean esté disponible)\n",
        "# universe_monthly, prices_monthly = define_investment_universe(\n",
        "#     price_data_clean, \n",
        "#     lookback_months=13, \n",
        "#     min_trading_days=0.8\n",
        "# )\n",
        "\n",
        "# print(\"\\n=== UNIVERSO MENSUAL ===\")\n",
        "# print(f\"Total de meses: {len(universe_monthly)}\")\n",
        "# print(f\"Promedio de activos elegibles por mes: {universe_monthly.apply(lambda x: len([a for a in x if pd.notna(a)]), axis=1).mean():.0f}\")\n",
        "\n",
        "# print(\"\\n=== EJEMPLO: Primer mes ===\")\n",
        "# first_month = universe_monthly.index[0]\n",
        "# print(f\"Fecha: {first_month}\")\n",
        "# print(f\"Activos elegibles: {len([a for a in universe_monthly.loc[first_month] if pd.notna(a)])}\")\n",
        "\n",
        "print(\"⚠️  Ejecutar definición de universo después de validar datos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Guardado de Datos Preparados {#guardado}\n",
        "\n",
        "Guardado de datos procesados para uso en notebooks posteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear directorio de datos si no existe\n",
        "data_dir = '../data'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Guardar datos procesados (descomentar cuando estén disponibles)\n",
        "# price_data_clean.to_parquet(f'{data_dir}/price_data_clean.parquet')\n",
        "# prices_monthly.to_parquet(f'{data_dir}/prices_monthly.parquet')\n",
        "\n",
        "# Guardar universo mensual como CSV para fácil lectura\n",
        "# universe_monthly.to_csv(f'{data_dir}/universe_monthly.csv')\n",
        "\n",
        "print(\"\\n=== RESUMEN DEL NOTEBOOK 1 ===\")\n",
        "print(\"✓ Configuración del entorno\")\n",
        "print(\"✓ Funciones de carga y validación creadas\")\n",
        "print(\"✓ Estructura lista para procesar datos\")\n",
        "print(\"\\n⚠️  IMPORTANTE: Ejecutar todas las celdas con datos reales\")\n",
        "print(\"⚠️  Los datos deben guardarse en formato Parquet para eficiencia\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
