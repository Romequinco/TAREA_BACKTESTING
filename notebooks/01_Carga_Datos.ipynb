{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 1: Carga de Datos\n",
        "\n",
        "## Objetivo\n",
        "Este notebook se encarga exclusivamente de descargar y almacenar los datos necesarios para toda la práctica.\n",
        "\n",
        "## Estructura\n",
        "1. Imports y Configuración\n",
        "2. Verificación del Archivo desde Google Drive\n",
        "3. Carga del Dataset\n",
        "4. Separación del Benchmark\n",
        "5. Guardado del Dataset Completo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports y Configuración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Librerías importadas correctamente\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import yfinance as yf\n",
        "\n",
        "# Configuración de pandas para mejor visualización\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "\n",
        "# Constantes\n",
        "DATA_RAW_DIR = '../datos/raw'\n",
        "BENCHMARK_TICKER = 'SPY'\n",
        "START_DATE = '2015-01-01'\n",
        "PARQUET_NAME = 'sp500_history.parquet'\n",
        "\n",
        "print('Librerías importadas correctamente')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Verificación del Archivo desde Google Drive\n",
        "\n",
        "**Importante:** El archivo debe descargarse manualmente desde Google Drive y colocarse en la carpeta `datos/raw/` con el nombre `historical_prices.parquet`.\n",
        "\n",
        "Enlace: https://drive.google.com/file/d/1nvubXdAu0EONlrP_yrURZbnPhBQ-uDaB/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivo encontrado en: ../datos/raw/sp500_history.parquet\n"
          ]
        }
      ],
      "source": [
        "def find_parquet(filename):\n",
        "    \"\"\"\n",
        "    Busca el archivo parquet en diferentes ubicaciones posibles.\n",
        "    \n",
        "    Parámetros:\n",
        "    -----------\n",
        "    filename : str\n",
        "        Nombre del archivo a buscar\n",
        "    \n",
        "    Retorna:\n",
        "    --------\n",
        "    str o None\n",
        "        Ruta al archivo si se encuentra, None en caso contrario\n",
        "    \"\"\"\n",
        "    # Lista de rutas posibles a probar\n",
        "    possible_paths = [\n",
        "        f'../datos/raw/{filename}',\n",
        "        f'datos/raw/{filename}',\n",
        "        f'../{filename}',\n",
        "        filename,\n",
        "        f'../../datos/raw/{filename}',\n",
        "        f'../../../datos/raw/{filename}',\n",
        "    ]\n",
        "    \n",
        "    for path in possible_paths:\n",
        "        try:\n",
        "            # Intentar abrir el archivo con pyarrow directamente\n",
        "            parquet_file = pq.ParquetFile(path)\n",
        "            parquet_file.close()\n",
        "            return path\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "        except Exception:\n",
        "            # Si hay otro error (no FileNotFoundError), el archivo existe\n",
        "            # pero hay un problema al leerlo, lo intentamos de todas formas\n",
        "            return path\n",
        "    \n",
        "    return None\n",
        "\n",
        "\n",
        "# Resolver ruta del Parquet de forma robusta\n",
        "parquet_path = find_parquet(PARQUET_NAME)\n",
        "\n",
        "if parquet_path is None:\n",
        "    raise FileNotFoundError(\n",
        "        f'No se encuentra el archivo: {PARQUET_NAME}. '\n",
        "        f'Asegúrate de estar dentro de la carpeta del proyecto o sube el parquet.'\n",
        "    )\n",
        "\n",
        "downloaded_file_path = parquet_path\n",
        "print(f'Archivo encontrado en: {downloaded_file_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Carga del Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando dataset desde: ../datos/raw/sp500_history.parquet\n",
            "Dataset cargado correctamente\n",
            "\n",
            "=== INFORMACIÓN DEL DATASET ===\n",
            "Shape del dataset: (7250110, 14)\n",
            "Columnas: 14\n",
            "Filas: 7250110\n",
            "Columnas disponibles: ['date', 'symbol', 'assetid', 'security_name', 'sector', 'industry', 'subsector', 'in_sp500', 'open', 'high', 'low', 'close', 'volume', 'unadjusted_close']\n",
            "\n",
            "Convirtiendo columna date a datetime...\n",
            "\n",
            "Rango de fechas disponible:\n",
            "  Fecha inicio: 1990-01-02 00:00:00\n",
            "  Fecha fin: 2026-01-30 00:00:00\n",
            "\n",
            "Número de tickers únicos: 1289\n",
            "Tickers disponibles: ['A', 'AABA-201910', 'AAL', 'AAL-199702', 'AAMRQ-201312', 'AAP', 'AAPL', 'AAV-199901', 'ABBV', 'ABI-200811', ...]\n",
            "\n",
            "=== INFORMACIÓN DETALLADA DEL DATASET ===\n",
            "Total de registros: 7,250,110\n",
            "Total de columnas: 13\n",
            "\n",
            "Tipos de datos por columna:\n",
            "symbol               object\n",
            "assetid               int64\n",
            "security_name        object\n",
            "sector               object\n",
            "industry             object\n",
            "subsector            object\n",
            "in_sp500              int32\n",
            "open                float32\n",
            "high                float32\n",
            "low                 float32\n",
            "close               float32\n",
            "volume              float32\n",
            "unadjusted_close    float32\n",
            "dtype: object\n",
            "\n",
            "=== PRIMERAS 10 FILAS DEL DATASET ===\n",
            "                  symbol  assetid                     security_name  \\\n",
            "date                                                                  \n",
            "1990-01-02    TXU-200710   131697                   TXU Corp Common   \n",
            "1990-01-02           ASH   143553                Ashland Inc Common   \n",
            "1990-01-02    ASC-199906   261386         American Stores Co Common   \n",
            "1990-01-02     AS-199909   261680                  Armco Inc Common   \n",
            "1990-01-02          ORCL   130102                Oracle Corp Common   \n",
            "1990-01-02    ORX-199902   261029             Oryx Energy Co Common   \n",
            "1990-01-02    ARG-201605   145669                 Airgas Inc Common   \n",
            "1990-01-02  OWENQ-200610   136070              Owens-Corning Common   \n",
            "1990-01-02           OXY   135802  Occidental Petroleum Corp Common   \n",
            "1990-01-02    PAC-199703   259164      Pacific Telesis Group Common   \n",
            "\n",
            "                            sector  \\\n",
            "date                                 \n",
            "1990-01-02               Utilities   \n",
            "1990-01-02               Materials   \n",
            "1990-01-02        Consumer Staples   \n",
            "1990-01-02               Materials   \n",
            "1990-01-02  Information Technology   \n",
            "1990-01-02                  Energy   \n",
            "1990-01-02               Materials   \n",
            "1990-01-02             Industrials   \n",
            "1990-01-02                  Energy   \n",
            "1990-01-02  Communication Services   \n",
            "\n",
            "                                                     industry  \\\n",
            "date                                                            \n",
            "1990-01-02  Independent Power and Renewable Electricity Pr...   \n",
            "1990-01-02                                          Chemicals   \n",
            "1990-01-02             Consumer Staples Distribution & Retail   \n",
            "1990-01-02                                    Metals & Mining   \n",
            "1990-01-02                                           Software   \n",
            "1990-01-02                        Oil, Gas & Consumable Fuels   \n",
            "1990-01-02                                          Chemicals   \n",
            "1990-01-02                                  Building Products   \n",
            "1990-01-02                        Oil, Gas & Consumable Fuels   \n",
            "1990-01-02             Diversified Telecommunication Services   \n",
            "\n",
            "                                               subsector  in_sp500    open  \\\n",
            "date                                                                         \n",
            "1990-01-02  Independent Power Producers & Energy Traders         1  6.5720   \n",
            "1990-01-02                           Specialty Chemicals         1  5.9434   \n",
            "1990-01-02                                          None         1  6.0275   \n",
            "1990-01-02                                          None         1 10.0468   \n",
            "1990-01-02                              Systems Software         1  0.4605   \n",
            "1990-01-02                                          None         1 39.2352   \n",
            "1990-01-02                              Industrial Gases         0  2.3890   \n",
            "1990-01-02                             Building Products         1 20.4755   \n",
            "1990-01-02                          Integrated Oil & Gas         1  3.9153   \n",
            "1990-01-02                                          None         1 19.8974   \n",
            "\n",
            "              high     low   close        volume  unadjusted_close  \n",
            "date                                                                \n",
            "1990-01-02  6.5953  6.5252  6.5953  6347346.5000           35.2500  \n",
            "1990-01-02  5.9621  5.8496  5.8871  1196076.6250           39.2500  \n",
            "1990-01-02  6.0939  6.0275  6.0939   600691.3750           57.3750  \n",
            "1990-01-02 10.6378 10.0468 10.6378   229910.7031           11.2500  \n",
            "1990-01-02  0.4778  0.4531  0.4753 44582660.0000           24.1250  \n",
            "1990-01-02 39.6798 38.7906 39.3463   140128.6406           44.2500  \n",
            "1990-01-02  2.4151  2.3629  2.4020    75643.8594           23.0000  \n",
            "1990-01-02 20.9899 20.4755 20.9899    76050.7656           25.5000  \n",
            "1990-01-02  4.0157  3.8986  3.9990  3837675.0000           29.8750  \n",
            "1990-01-02 20.5490 19.8974 20.5490  1377457.5000           51.2500  \n",
            "\n",
            "=== ÚLTIMAS 10 FILAS DEL DATASET ===\n",
            "           symbol  assetid                         security_name  \\\n",
            "date                                                               \n",
            "2026-01-30    MSI   137593         Motorola Solutions Inc Common   \n",
            "2026-01-30    VFC   147728                      V.F. Corp Common   \n",
            "2026-01-30    ADP   139812  Automatic Data Processing Inc Common   \n",
            "2026-01-30      J   128591           Jacobs Solutions Inc Common   \n",
            "2026-01-30    GPC   132119               Genuine Parts Co Common   \n",
            "2026-01-30     SW   393857           Smurfit Westrock PLC Common   \n",
            "2026-01-30     AN   124589                 AutoNation Inc Common   \n",
            "2026-01-30     GD   142332          General Dynamics Corp Common   \n",
            "2026-01-30   GDDY  2029076            GoDaddy Inc Class A Common   \n",
            "2026-01-30    ZTS   741452             Zoetis Inc Class A Common   \n",
            "\n",
            "                            sector                         industry  \\\n",
            "date                                                                  \n",
            "2026-01-30  Information Technology         Communications Equipment   \n",
            "2026-01-30  Consumer Discretionary  Textiles Apparel & Luxury Goods   \n",
            "2026-01-30             Industrials            Professional Services   \n",
            "2026-01-30             Industrials            Professional Services   \n",
            "2026-01-30  Consumer Discretionary                     Distributors   \n",
            "2026-01-30               Materials           Containers & Packaging   \n",
            "2026-01-30  Consumer Discretionary                 Specialty Retail   \n",
            "2026-01-30             Industrials              Aerospace & Defense   \n",
            "2026-01-30  Information Technology                      IT Services   \n",
            "2026-01-30             Health Care                  Pharmaceuticals   \n",
            "\n",
            "                                                 subsector  in_sp500     open  \\\n",
            "date                                                                            \n",
            "2026-01-30                        Communications Equipment         1 400.7300   \n",
            "2026-01-30             Apparel, Accessories & Luxury Goods         0  20.0100   \n",
            "2026-01-30            Human Resource & Employment Services         1 245.0650   \n",
            "2026-01-30                  Research & Consulting Services         1 135.4700   \n",
            "2026-01-30                                    Distributors         1 137.5000   \n",
            "2026-01-30  Paper & Plastic Packaging Products & Materials         1  41.7100   \n",
            "2026-01-30                               Automotive Retail         0 206.4200   \n",
            "2026-01-30                             Aerospace & Defense         1 347.2500   \n",
            "2026-01-30              Internet Services & Infrastructure         1  99.5900   \n",
            "2026-01-30                                 Pharmaceuticals         1 121.1600   \n",
            "\n",
            "               high      low    close       volume  unadjusted_close  \n",
            "date                                                                  \n",
            "2026-01-30 403.0950 397.4800 402.5400  957674.0000          402.5400  \n",
            "2026-01-30  20.4150  19.5400  19.5900 8168827.0000           19.5900  \n",
            "2026-01-30 247.0000 243.6800 246.8200 3568356.0000          246.8200  \n",
            "2026-01-30 136.6250 133.4850 135.2600  830381.0000          135.2600  \n",
            "2026-01-30 138.9900 136.2601 138.9900 2047353.0000          138.9900  \n",
            "2026-01-30  41.7950  40.6900  41.6300 5454594.0000           41.6300  \n",
            "2026-01-30 207.1200 203.7000 204.9800  506586.0000          204.9800  \n",
            "2026-01-30 353.2800 347.1600 351.0900 2058331.0000          351.0900  \n",
            "2026-01-30 100.8700  98.8000 100.5200 2007810.0000          100.5200  \n",
            "2026-01-30 124.8700 120.0600 124.8200 5247316.0000          124.8200  \n"
          ]
        }
      ],
      "source": [
        "def load_parquet_dataset(file_path):\n",
        "    \"\"\"\n",
        "    Carga un dataset desde un archivo Parquet usando pyarrow directamente.\n",
        "    \n",
        "    Parámetros:\n",
        "    -----------\n",
        "    file_path : str\n",
        "        Ruta al archivo Parquet\n",
        "    \n",
        "    Retorna:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        DataFrame con los datos cargados\n",
        "    \"\"\"\n",
        "    print(f'Cargando dataset desde: {file_path}')\n",
        "    try:\n",
        "        # Usar pyarrow directamente para evitar conflictos de tipos\n",
        "        table = pq.read_table(file_path)\n",
        "        df = table.to_pandas()\n",
        "        print('Dataset cargado correctamente')\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f'Error al cargar el archivo con pyarrow: {str(e)}')\n",
        "        print('Intentando con pandas directamente...')\n",
        "        try:\n",
        "            # Si falla pyarrow, intentar con pandas\n",
        "            df = pd.read_parquet(file_path, engine='pyarrow')\n",
        "            print('Dataset cargado correctamente')\n",
        "            return df\n",
        "        except Exception as e2:\n",
        "            print(f'Error al cargar con pandas: {str(e2)}')\n",
        "            raise\n",
        "\n",
        "\n",
        "# Cargar el dataset completo\n",
        "dataset = load_parquet_dataset(downloaded_file_path)\n",
        "\n",
        "# Verificar estructura básica\n",
        "print('\\n=== INFORMACIÓN DEL DATASET ===')\n",
        "print(f'Shape del dataset: {dataset.shape}')\n",
        "print(f'Columnas: {len(dataset.columns)}')\n",
        "print(f'Filas: {len(dataset)}')\n",
        "print(f'Columnas disponibles: {list(dataset.columns)}')\n",
        "\n",
        "# Si el dataset tiene columna 'date', convertirla a datetime y usarla como índice\n",
        "if 'date' in dataset.columns:\n",
        "    print('\\nConvirtiendo columna date a datetime...')\n",
        "    dataset['date'] = pd.to_datetime(dataset['date'], errors='coerce')\n",
        "    dataset = dataset.set_index('date')\n",
        "    dataset = dataset.sort_index()\n",
        "elif not isinstance(dataset.index, pd.DatetimeIndex):\n",
        "    print('Convirtiendo índice a DatetimeIndex...')\n",
        "    dataset.index = pd.to_datetime(dataset.index, errors='coerce')\n",
        "    dataset = dataset.sort_index()\n",
        "\n",
        "# Mostrar rango de fechas\n",
        "print(f'\\nRango de fechas disponible:')\n",
        "print(f'  Fecha inicio: {dataset.index.min()}')\n",
        "print(f'  Fecha fin: {dataset.index.max()}')\n",
        "\n",
        "# Contar tickers únicos\n",
        "if 'symbol' in dataset.columns:\n",
        "    tickers = sorted(dataset['symbol'].unique())\n",
        "    print(f'\\nNúmero de tickers únicos: {len(tickers)}')\n",
        "    tickers_display = tickers[:10]\n",
        "    tickers_str = str(tickers_display)\n",
        "    if len(tickers) > 10:\n",
        "        tickers_str = tickers_str[:-1] + ', ...]'\n",
        "    print(f'Tickers disponibles: {tickers_str}')\n",
        "elif isinstance(dataset.columns, pd.MultiIndex):\n",
        "    tickers = sorted(dataset.columns.get_level_values(0).unique())\n",
        "    print(f'\\nNúmero de tickers únicos: {len(tickers)}')\n",
        "    tickers_display = tickers[:10]\n",
        "    tickers_str = str(tickers_display)\n",
        "    if len(tickers) > 10:\n",
        "        tickers_str = tickers_str[:-1] + ', ...]'\n",
        "    print(f'Tickers disponibles: {tickers_str}')\n",
        "else:\n",
        "    tickers = sorted(dataset.columns.unique())\n",
        "    print(f'\\nNúmero de columnas: {len(tickers)}')\n",
        "    tickers_display = tickers[:10]\n",
        "    tickers_str = str(tickers_display)\n",
        "    if len(tickers) > 10:\n",
        "        tickers_str = tickers_str[:-1] + ', ...]'\n",
        "    print(f'Columnas disponibles: {tickers_str}')\n",
        "\n",
        "# Mostrar información detallada del dataset\n",
        "print('\\n=== INFORMACIÓN DETALLADA DEL DATASET ===')\n",
        "print(f'Total de registros: {len(dataset):,}')\n",
        "print(f'Total de columnas: {len(dataset.columns)}')\n",
        "print(f'\\nTipos de datos por columna:')\n",
        "print(dataset.dtypes)\n",
        "\n",
        "# Mostrar primeras filas para verificación\n",
        "print('\\n=== PRIMERAS 10 FILAS DEL DATASET ===')\n",
        "with pd.option_context('display.max_columns', None, \n",
        "                       'display.max_rows', 10,\n",
        "                       'display.width', None,\n",
        "                       'display.max_colwidth', 50):\n",
        "    print(dataset.head(10))\n",
        "\n",
        "# Mostrar últimas filas\n",
        "print('\\n=== ÚLTIMAS 10 FILAS DEL DATASET ===')\n",
        "with pd.option_context('display.max_columns', None, \n",
        "                       'display.max_rows', 10,\n",
        "                       'display.width', None,\n",
        "                       'display.max_colwidth', 50):\n",
        "    print(dataset.tail(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Descarga del Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descargando datos de SPY desde 2015-01-01...\n",
            "Benchmark SPY descargado correctamente\n",
            "Shape del benchmark: (2800, 13)\n",
            "Rango de fechas: 2015-01-02 00:00:00-05:00 a 2026-02-20 00:00:00-05:00\n",
            "Columnas: ['symbol', 'assetid', 'security_name', 'sector', 'industry', 'subsector', 'in_sp500', 'open', 'high', 'low', 'close', 'volume', 'unadjusted_close']\n",
            "\n",
            "=== INFORMACIÓN DETALLADA DEL BENCHMARK ===\n",
            "Total de registros: 2,800\n",
            "Total de columnas: 13\n",
            "Número de días: 2800\n",
            "\n",
            "Tipos de datos por columna:\n",
            "symbol               object\n",
            "assetid               int64\n",
            "security_name        object\n",
            "sector               object\n",
            "industry             object\n",
            "subsector            object\n",
            "in_sp500              int64\n",
            "open                float64\n",
            "high                float64\n",
            "low                 float64\n",
            "close               float64\n",
            "volume                int64\n",
            "unadjusted_close    float64\n",
            "dtype: object\n",
            "\n",
            "=== ESTADÍSTICAS DE PRECIOS ===\n",
            "           open      high       low     close\n",
            "count 2800.0000 2800.0000 2800.0000 2800.0000\n",
            "mean   342.1400  343.9840  340.1211  342.1966\n",
            "std    145.0561  145.7333  144.2687  145.0706\n",
            "min    154.5401  156.0318  152.8816  154.9809\n",
            "25%    220.9636  223.6091  218.8683  220.8984\n",
            "50%    304.5580  306.2944  303.1651  304.7183\n",
            "75%    425.3793  427.5981  423.1918  425.7345\n",
            "max    697.0500  697.8400  693.9400  695.4900\n",
            "\n",
            "=== PRIMERAS 10 FILAS DEL BENCHMARK ===\n",
            "                          symbol  assetid  \\\n",
            "date                                        \n",
            "2015-01-02 00:00:00-05:00    SPY        0   \n",
            "2015-01-05 00:00:00-05:00    SPY        0   \n",
            "2015-01-06 00:00:00-05:00    SPY        0   \n",
            "2015-01-07 00:00:00-05:00    SPY        0   \n",
            "2015-01-08 00:00:00-05:00    SPY        0   \n",
            "2015-01-09 00:00:00-05:00    SPY        0   \n",
            "2015-01-12 00:00:00-05:00    SPY        0   \n",
            "2015-01-13 00:00:00-05:00    SPY        0   \n",
            "2015-01-14 00:00:00-05:00    SPY        0   \n",
            "2015-01-15 00:00:00-05:00    SPY        0   \n",
            "\n",
            "                                                 security_name   sector  \\\n",
            "date                                                                      \n",
            "2015-01-02 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2015-01-05 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2015-01-06 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2015-01-07 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2015-01-08 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2015-01-09 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2015-01-12 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2015-01-13 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2015-01-14 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2015-01-15 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "\n",
            "                          industry subsector  in_sp500     open     high  \\\n",
            "date                                                                       \n",
            "2015-01-02 00:00:00-05:00  Unknown   Unknown         1 171.3785 171.7937   \n",
            "2015-01-05 00:00:00-05:00  Unknown   Unknown         1 169.5433 169.7094   \n",
            "2015-01-06 00:00:00-05:00  Unknown   Unknown         1 167.8161 168.3392   \n",
            "2015-01-07 00:00:00-05:00  Unknown   Unknown         1 167.2597 168.3392   \n",
            "2015-01-08 00:00:00-05:00  Unknown   Unknown         1 169.4104 171.1958   \n",
            "2015-01-09 00:00:00-05:00  Unknown   Unknown         1 171.3951 171.4117   \n",
            "2015-01-12 00:00:00-05:00  Unknown   Unknown         1 169.7426 169.9004   \n",
            "2015-01-13 00:00:00-05:00  Unknown   Unknown         1 169.5018 170.6311   \n",
            "2015-01-14 00:00:00-05:00  Unknown   Unknown         1 165.7899 166.9940   \n",
            "2015-01-15 00:00:00-05:00  Unknown   Unknown         1 167.4341 167.7496   \n",
            "\n",
            "                               low    close     volume  unadjusted_close  \n",
            "date                                                                      \n",
            "2015-01-02 00:00:00-05:00 169.5516 170.5896  121465900          170.5896  \n",
            "2015-01-05 00:00:00-05:00 167.2016 167.5088  169632600          167.5088  \n",
            "2015-01-06 00:00:00-05:00 165.1339 165.9310  209151400          165.9310  \n",
            "2015-01-07 00:00:00-05:00 166.8113 167.9987  125346700          167.9987  \n",
            "2015-01-08 00:00:00-05:00 169.3938 170.9799  147217800          170.9799  \n",
            "2015-01-09 00:00:00-05:00 168.9952 169.6097  158567300          169.6097  \n",
            "2015-01-12 00:00:00-05:00 167.6749 168.2811  144396100          168.2811  \n",
            "2015-01-13 00:00:00-05:00 166.5040 167.8078  214553300          167.8078  \n",
            "2015-01-14 00:00:00-05:00 164.8930 166.7947  192991100          166.7947  \n",
            "2015-01-15 00:00:00-05:00 165.1505 165.2667  176613900          165.2667  \n",
            "\n",
            "=== ÚLTIMAS 10 FILAS DEL BENCHMARK ===\n",
            "                          symbol  assetid  \\\n",
            "date                                        \n",
            "2026-02-06 00:00:00-05:00    SPY        0   \n",
            "2026-02-09 00:00:00-05:00    SPY        0   \n",
            "2026-02-10 00:00:00-05:00    SPY        0   \n",
            "2026-02-11 00:00:00-05:00    SPY        0   \n",
            "2026-02-12 00:00:00-05:00    SPY        0   \n",
            "2026-02-13 00:00:00-05:00    SPY        0   \n",
            "2026-02-17 00:00:00-05:00    SPY        0   \n",
            "2026-02-18 00:00:00-05:00    SPY        0   \n",
            "2026-02-19 00:00:00-05:00    SPY        0   \n",
            "2026-02-20 00:00:00-05:00    SPY        0   \n",
            "\n",
            "                                                 security_name   sector  \\\n",
            "date                                                                      \n",
            "2026-02-06 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2026-02-09 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2026-02-10 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2026-02-11 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2026-02-12 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2026-02-13 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2026-02-17 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2026-02-18 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2026-02-19 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "2026-02-20 00:00:00-05:00  State Street SPDR S&P 500 ETF Trust  Unknown   \n",
            "\n",
            "                          industry subsector  in_sp500     open     high  \\\n",
            "date                                                                       \n",
            "2026-02-06 00:00:00-05:00  Unknown   Unknown         1 681.4600 692.3100   \n",
            "2026-02-09 00:00:00-05:00  Unknown   Unknown         1 689.4200 695.8700   \n",
            "2026-02-10 00:00:00-05:00  Unknown   Unknown         1 694.9500 696.5400   \n",
            "2026-02-11 00:00:00-05:00  Unknown   Unknown         1 696.3900 697.1400   \n",
            "2026-02-12 00:00:00-05:00  Unknown   Unknown         1 694.2400 695.3500   \n",
            "2026-02-13 00:00:00-05:00  Unknown   Unknown         1 681.6900 686.2800   \n",
            "2026-02-17 00:00:00-05:00  Unknown   Unknown         1 680.1400 684.9400   \n",
            "2026-02-18 00:00:00-05:00  Unknown   Unknown         1 684.0200 689.1500   \n",
            "2026-02-19 00:00:00-05:00  Unknown   Unknown         1 683.8400 686.1800   \n",
            "2026-02-20 00:00:00-05:00  Unknown   Unknown         1 682.3200 690.0600   \n",
            "\n",
            "                               low    close     volume  unadjusted_close  \n",
            "date                                                                      \n",
            "2026-02-06 00:00:00-05:00 680.8500 690.6200   89127600          690.6200  \n",
            "2026-02-09 00:00:00-05:00 688.3400 693.9500   73885200          693.9500  \n",
            "2026-02-10 00:00:00-05:00 691.6600 692.1200   65185700          692.1200  \n",
            "2026-02-11 00:00:00-05:00 689.1800 691.9600   76353900          691.9600  \n",
            "2026-02-12 00:00:00-05:00 680.3700 681.2700  118829000          681.2700  \n",
            "2026-02-13 00:00:00-05:00 677.5200 681.7500   96267500          681.7500  \n",
            "2026-02-17 00:00:00-05:00 675.7800 682.8500   81354700          682.8500  \n",
            "2026-02-18 00:00:00-05:00 682.8300 686.2900   73570300          686.2900  \n",
            "2026-02-19 00:00:00-05:00 681.5500 684.4800   58649400          684.4800  \n",
            "2026-02-20 00:00:00-05:00 681.7300 689.4300   99952100          689.4300  \n",
            "\n",
            "Benchmark guardado en: ../datos/raw/spy_data.parquet\n"
          ]
        }
      ],
      "source": [
        "def download_benchmark_data(benchmark_ticker, start_date):\n",
        "    \"\"\"\n",
        "    Descarga los datos del benchmark desde yfinance y los formatea\n",
        "    con la misma estructura que el dataset del parquet.\n",
        "    \n",
        "    Parámetros:\n",
        "    -----------\n",
        "    benchmark_ticker : str\n",
        "        Símbolo del ticker del benchmark (ej: 'SPY')\n",
        "    start_date : str\n",
        "        Fecha de inicio en formato 'YYYY-MM-DD'\n",
        "    \n",
        "    Retorna:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        DataFrame con datos del benchmark con las mismas columnas que el parquet\n",
        "    \"\"\"\n",
        "    print(f'Descargando datos de {benchmark_ticker} desde {start_date}...')\n",
        "    \n",
        "    try:\n",
        "        ticker = yf.Ticker(benchmark_ticker)\n",
        "        hist = ticker.history(start=start_date)\n",
        "        \n",
        "        if hist.empty:\n",
        "            raise ValueError(f'No se pudieron descargar datos de {benchmark_ticker}')\n",
        "        \n",
        "        # Obtener información del ticker\n",
        "        info = ticker.info\n",
        "        \n",
        "        # Formatear datos con la misma estructura que el parquet\n",
        "        benchmark_data = pd.DataFrame({\n",
        "            'symbol': benchmark_ticker,\n",
        "            'assetid': 0,  # No disponible en yfinance\n",
        "            'security_name': info.get('longName', benchmark_ticker),\n",
        "            'sector': info.get('sector', 'Unknown'),\n",
        "            'industry': info.get('industry', 'Unknown'),\n",
        "            'subsector': info.get('industryDisp', 'Unknown'),\n",
        "            'in_sp500': 1,  # SPY es el ETF del S&P 500\n",
        "            'open': hist['Open'].values,\n",
        "            'high': hist['High'].values,\n",
        "            'low': hist['Low'].values,\n",
        "            'close': hist['Close'].values,\n",
        "            'volume': hist['Volume'].values,\n",
        "            'unadjusted_close': hist['Close'].values  # yfinance no proporciona unadjusted\n",
        "        })\n",
        "        \n",
        "        # Usar la fecha como índice\n",
        "        benchmark_data.index = hist.index\n",
        "        benchmark_data.index.name = 'date'\n",
        "        \n",
        "        # Ordenar por fecha\n",
        "        benchmark_data = benchmark_data.sort_index()\n",
        "        \n",
        "        print(f'Benchmark {benchmark_ticker} descargado correctamente')\n",
        "        print(f'Shape del benchmark: {benchmark_data.shape}')\n",
        "        print(f'Rango de fechas: {benchmark_data.index.min()} a {benchmark_data.index.max()}')\n",
        "        print(f'Columnas: {list(benchmark_data.columns)}')\n",
        "        \n",
        "        return benchmark_data\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f'Error al descargar {benchmark_ticker}: {str(e)}')\n",
        "        raise\n",
        "\n",
        "\n",
        "# Descargar datos del benchmark SPY\n",
        "spy_data = download_benchmark_data(BENCHMARK_TICKER, START_DATE)\n",
        "\n",
        "# Mostrar información detallada del benchmark\n",
        "print('\\n=== INFORMACIÓN DETALLADA DEL BENCHMARK ===')\n",
        "print(f'Total de registros: {len(spy_data):,}')\n",
        "print(f'Total de columnas: {len(spy_data.columns)}')\n",
        "print(f'Número de días: {len(spy_data)}')\n",
        "print(f'\\nTipos de datos por columna:')\n",
        "print(spy_data.dtypes)\n",
        "\n",
        "# Estadísticas básicas de precios\n",
        "print('\\n=== ESTADÍSTICAS DE PRECIOS ===')\n",
        "price_cols = ['open', 'high', 'low', 'close']\n",
        "with pd.option_context('display.max_columns', None):\n",
        "    print(spy_data[price_cols].describe())\n",
        "\n",
        "# Mostrar primeras filas\n",
        "print('\\n=== PRIMERAS 10 FILAS DEL BENCHMARK ===')\n",
        "with pd.option_context('display.max_columns', None, \n",
        "                       'display.max_rows', 10,\n",
        "                       'display.width', None,\n",
        "                       'display.max_colwidth', 50):\n",
        "    print(spy_data.head(10))\n",
        "\n",
        "# Mostrar últimas filas\n",
        "print('\\n=== ÚLTIMAS 10 FILAS DEL BENCHMARK ===')\n",
        "with pd.option_context('display.max_columns', None, \n",
        "                       'display.max_rows', 10,\n",
        "                       'display.width', None,\n",
        "                       'display.max_colwidth', 50):\n",
        "    print(spy_data.tail(10))\n",
        "\n",
        "# Guardar benchmark usando pyarrow directamente\n",
        "spy_output_path = f'{DATA_RAW_DIR}/spy_data.parquet'\n",
        "try:\n",
        "    # Convertir DataFrame a tabla de pyarrow y guardar\n",
        "    table = pa.Table.from_pandas(spy_data)\n",
        "    pq.write_table(table, spy_output_path)\n",
        "    print(f'\\nBenchmark guardado en: {spy_output_path}')\n",
        "except (OSError, FileNotFoundError):\n",
        "    print(f'Error: No se pudo crear el directorio. '\n",
        "          f'Asegúrate de que {DATA_RAW_DIR} existe.')\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f'Error al guardar el benchmark: {str(e)}')\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Guardado del Dataset Completo\n",
        "\n",
        "Guarda el dataset completo procesado (todos los tickers del S&P 500) en `tickers_data.parquet`. Diferencias: `sp500_history.parquet` es el original sin procesar, `spy_data.parquet` contiene solo el benchmark SPY, y `tickers_data.parquet` es el dataset completo procesado y listo para limpiar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Guardando dataset en: ../datos/raw/tickers_data.parquet\n",
            "Dataset guardado exitosamente\n",
            "\n",
            "=== RESUMEN DEL NOTEBOOK 1 ===\n",
            "Proceso completado exitosamente\n",
            "\n",
            "Archivos generados:\n",
            "  1. ../datos/raw/sp500_history.parquet\n",
            "  2. ../datos/raw/spy_data.parquet\n",
            "  3. ../datos/raw/tickers_data.parquet\n",
            "\n",
            "Información del dataset:\n",
            "  - Total de tickers: 1289\n",
            "  - Rango de fechas: 1990-01-02 00:00:00 a 2026-01-30 00:00:00\n",
            "  - Total de registros: 7250110\n",
            "\n",
            "Notebook 1 completado correctamente\n"
          ]
        }
      ],
      "source": [
        "def save_dataset_parquet(df, output_path):\n",
        "    \"\"\"\n",
        "    Guarda un DataFrame en formato Parquet usando pyarrow directamente.\n",
        "    \n",
        "    Parámetros:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame a guardar\n",
        "    output_path : str\n",
        "        Ruta donde guardar el archivo\n",
        "    \"\"\"\n",
        "    print(f'Guardando dataset en: {output_path}')\n",
        "    try:\n",
        "        # Convertir DataFrame a tabla de pyarrow y guardar\n",
        "        table = pa.Table.from_pandas(df)\n",
        "        pq.write_table(table, output_path)\n",
        "        print(f'Dataset guardado exitosamente')\n",
        "    except Exception as e:\n",
        "        print(f'Error al guardar el dataset: {str(e)}')\n",
        "        raise\n",
        "\n",
        "\n",
        "# Guardar dataset completo de tickers\n",
        "tickers_output_path = f'{DATA_RAW_DIR}/tickers_data.parquet'\n",
        "try:\n",
        "    save_dataset_parquet(dataset, tickers_output_path)\n",
        "except (OSError, FileNotFoundError):\n",
        "    print(f'Error: No se pudo crear el directorio. '\n",
        "          f'Asegúrate de que {DATA_RAW_DIR} existe.')\n",
        "    raise\n",
        "\n",
        "# Resumen final\n",
        "print('\\n=== RESUMEN DEL NOTEBOOK 1 ===')\n",
        "print('Proceso completado exitosamente')\n",
        "print(f'\\nArchivos generados:')\n",
        "print(f'  1. {downloaded_file_path}')\n",
        "print(f'  2. {spy_output_path}')\n",
        "print(f'  3. {tickers_output_path}')\n",
        "print(f'\\nInformación del dataset:')\n",
        "print(f'  - Total de tickers: {len(tickers)}')\n",
        "print(f'  - Rango de fechas: {dataset.index.min()} a {dataset.index.max()}')\n",
        "print(f'  - Total de registros: {len(dataset)}')\n",
        "print('\\nNotebook 1 completado correctamente')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
